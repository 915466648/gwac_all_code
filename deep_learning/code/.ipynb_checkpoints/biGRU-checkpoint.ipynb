{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用双向GRU对异常子序列进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d346cb8acb48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0minput_to_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_to_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32mD:\\Anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "input_dim = 10\n",
    "embedding_dim = 2\n",
    "embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "err = True\n",
    "if err:\n",
    "    #Any input more than input_dim - 1, here input_dim = 10\n",
    "    #Any input less than zero\n",
    "    input_to_embed = torch.tensor([10])\n",
    "else:\n",
    "    input_to_embed = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "embed = embedding(input_to_embed)\n",
    "print(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs...\n",
      "--------------------------------------------------\n",
      "[0m 3s] Epoch 1[400 / 15802]loss=0.0034410327672958372\n",
      "[0m 6s] Epoch 1[800 / 15802]loss=0.003476601243019104\n",
      "[0m 9s] Epoch 1[1200 / 15802]loss=0.0034718785683314005\n",
      "[0m 12s] Epoch 1[1600 / 15802]loss=0.00348155427724123\n",
      "[0m 16s] Epoch 1[2000 / 15802]loss=0.003455511897802353\n",
      "[0m 19s] Epoch 1[2400 / 15802]loss=0.0034375831733147303\n",
      "[0m 22s] Epoch 1[2800 / 15802]loss=0.0034124491470200677\n",
      "[0m 26s] Epoch 1[3200 / 15802]loss=0.003391187936067581\n",
      "[0m 29s] Epoch 1[3600 / 15802]loss=0.003362123270829519\n",
      "[0m 32s] Epoch 1[4000 / 15802]loss=0.003342007890343666\n",
      "[0m 35s] Epoch 1[4400 / 15802]loss=0.003341186737472361\n",
      "[0m 39s] Epoch 1[4800 / 15802]loss=0.0033306930710872013\n",
      "[0m 42s] Epoch 1[5200 / 15802]loss=0.003303604435462218\n",
      "[0m 45s] Epoch 1[5600 / 15802]loss=0.003276426919869014\n",
      "[0m 49s] Epoch 1[6000 / 15802]loss=0.0032994953493277234\n",
      "[0m 53s] Epoch 1[6400 / 15802]loss=0.0032891656924039126\n",
      "[0m 57s] Epoch 1[6800 / 15802]loss=0.0032570360513294446\n",
      "[1m 1s] Epoch 1[7200 / 15802]loss=0.0032551079243421555\n",
      "[1m 5s] Epoch 1[7600 / 15802]loss=0.003239437114251287\n",
      "[1m 9s] Epoch 1[8000 / 15802]loss=0.003212575662881136\n",
      "[1m 13s] Epoch 1[8400 / 15802]loss=0.003211896699808893\n",
      "[1m 17s] Epoch 1[8800 / 15802]loss=0.0031706860526041552\n",
      "[1m 21s] Epoch 1[9200 / 15802]loss=0.0031588644955469216\n",
      "[1m 25s] Epoch 1[9600 / 15802]loss=0.0031250755426784358\n",
      "[1m 29s] Epoch 1[10000 / 15802]loss=0.0031128999561071398\n",
      "[1m 34s] Epoch 1[10400 / 15802]loss=0.003105966199475985\n",
      "[1m 38s] Epoch 1[10800 / 15802]loss=0.0030641710233909113\n",
      "[1m 42s] Epoch 1[11200 / 15802]loss=0.003033431936055422\n",
      "[1m 46s] Epoch 1[11600 / 15802]loss=0.003058307237666229\n",
      "[1m 50s] Epoch 1[12000 / 15802]loss=0.003005135921140512\n",
      "[1m 54s] Epoch 1[12400 / 15802]loss=0.0029970737065999737\n",
      "[1m 58s] Epoch 1[12800 / 15802]loss=0.002954037149902433\n",
      "[2m 2s] Epoch 1[13200 / 15802]loss=0.0029472786007505476\n",
      "[2m 6s] Epoch 1[13600 / 15802]loss=0.00290739269598442\n",
      "[2m 10s] Epoch 1[14000 / 15802]loss=0.002915581424321447\n",
      "[2m 14s] Epoch 1[14400 / 15802]loss=0.0028799067334168487\n",
      "[2m 18s] Epoch 1[14800 / 15802]loss=0.002838844754607291\n",
      "[2m 22s] Epoch 1[15200 / 15802]loss=0.002799660243878239\n",
      "[2m 26s] Epoch 1[15600 / 15802]loss=0.0027604995238093228\n",
      "[2m 28s] Epoch 1[160 / 15802]loss=0.2809944933280349\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 2474/4000 61.85%\n",
      "========================1========================\n",
      "[2m 37s] Epoch 2[400 / 15802]loss=0.0012668519467115402\n",
      "[2m 41s] Epoch 2[800 / 15802]loss=0.0012829003110527992\n",
      "[2m 45s] Epoch 2[1200 / 15802]loss=0.0012608729427059492\n",
      "[2m 49s] Epoch 2[1600 / 15802]loss=0.0013171160314232112\n",
      "[2m 53s] Epoch 2[2000 / 15802]loss=0.00127379909157753\n",
      "[2m 57s] Epoch 2[2400 / 15802]loss=0.0015239135424296062\n",
      "[3m 1s] Epoch 2[2800 / 15802]loss=0.0015316066039460046\n",
      "[3m 5s] Epoch 2[3200 / 15802]loss=0.001498530968092382\n",
      "[3m 9s] Epoch 2[3600 / 15802]loss=0.0014735547163420254\n",
      "[3m 13s] Epoch 2[4000 / 15802]loss=0.0014296268261969089\n",
      "[3m 17s] Epoch 2[4400 / 15802]loss=0.0014243202690373768\n",
      "[3m 21s] Epoch 2[4800 / 15802]loss=0.0013895552636434634\n",
      "[3m 24s] Epoch 2[5200 / 15802]loss=0.0013761968738757646\n",
      "[3m 28s] Epoch 2[5600 / 15802]loss=0.0013307102689785616\n",
      "[3m 32s] Epoch 2[6000 / 15802]loss=0.00131843651086092\n",
      "[3m 36s] Epoch 2[6400 / 15802]loss=0.0013784773903898894\n",
      "[3m 40s] Epoch 2[6800 / 15802]loss=0.0013624529803500456\n",
      "[3m 44s] Epoch 2[7200 / 15802]loss=0.0013348192452556557\n",
      "[3m 48s] Epoch 2[7600 / 15802]loss=0.001312568864147914\n",
      "[3m 52s] Epoch 2[8000 / 15802]loss=0.0012971199713647365\n",
      "[3m 56s] Epoch 2[8400 / 15802]loss=0.0013472291951378186\n",
      "[4m 0s] Epoch 2[8800 / 15802]loss=0.001376178799705072\n",
      "[4m 4s] Epoch 2[9200 / 15802]loss=0.0013603354925694673\n",
      "[4m 8s] Epoch 2[9600 / 15802]loss=0.0013460473871479432\n",
      "[4m 12s] Epoch 2[10000 / 15802]loss=0.0013203399233520032\n",
      "[4m 16s] Epoch 2[10400 / 15802]loss=0.0013123004202945875\n",
      "[4m 20s] Epoch 2[10800 / 15802]loss=0.0013226885024320196\n",
      "[4m 24s] Epoch 2[11200 / 15802]loss=0.0013158129082460489\n",
      "[4m 28s] Epoch 2[11600 / 15802]loss=0.0013037147405075616\n",
      "[4m 32s] Epoch 2[12000 / 15802]loss=0.001288841525092721\n",
      "[4m 36s] Epoch 2[12400 / 15802]loss=0.001273422422067773\n",
      "[4m 40s] Epoch 2[12800 / 15802]loss=0.0012536935036769137\n",
      "[4m 44s] Epoch 2[13200 / 15802]loss=0.0012446474148468537\n",
      "[4m 48s] Epoch 2[13600 / 15802]loss=0.0012369677818873349\n",
      "[4m 52s] Epoch 2[14000 / 15802]loss=0.0012272603926914078\n",
      "[4m 56s] Epoch 2[14400 / 15802]loss=0.0012549302437239224\n",
      "[5m 1s] Epoch 2[14800 / 15802]loss=0.0012424890052627872\n",
      "[5m 5s] Epoch 2[15200 / 15802]loss=0.0012255545484980471\n",
      "[5m 9s] Epoch 2[15600 / 15802]loss=0.001222445488644716\n",
      "[5m 11s] Epoch 2[160 / 15802]loss=0.12100348114036023\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 2947/4000 73.67%\n",
      "========================2========================\n",
      "[5m 21s] Epoch 3[400 / 15802]loss=0.001474885791540146\n",
      "[5m 25s] Epoch 3[800 / 15802]loss=0.0015135757438838483\n",
      "[5m 29s] Epoch 3[1200 / 15802]loss=0.001441554216047128\n",
      "[5m 33s] Epoch 3[1600 / 15802]loss=0.001365099111571908\n",
      "[5m 37s] Epoch 3[2000 / 15802]loss=0.0012609297558665276\n",
      "[5m 41s] Epoch 3[2400 / 15802]loss=0.0012264483297864596\n",
      "[5m 45s] Epoch 3[2800 / 15802]loss=0.0011877551249095371\n",
      "[5m 49s] Epoch 3[3200 / 15802]loss=0.0011150375939905643\n",
      "[5m 53s] Epoch 3[3600 / 15802]loss=0.0011101128119561407\n",
      "[5m 57s] Epoch 3[4000 / 15802]loss=0.0010828671380877495\n",
      "[6m 1s] Epoch 3[4400 / 15802]loss=0.0010804495113817128\n",
      "[6m 5s] Epoch 3[4800 / 15802]loss=0.0010858052937934796\n",
      "[6m 9s] Epoch 3[5200 / 15802]loss=0.0010999276345738998\n",
      "[6m 13s] Epoch 3[5600 / 15802]loss=0.0011336174168224845\n",
      "[6m 17s] Epoch 3[6000 / 15802]loss=0.001118453126400709\n",
      "[6m 21s] Epoch 3[6400 / 15802]loss=0.001190161189297214\n",
      "[6m 25s] Epoch 3[6800 / 15802]loss=0.00116376537062666\n",
      "[6m 29s] Epoch 3[7200 / 15802]loss=0.0011457711054633061\n",
      "[6m 33s] Epoch 3[7600 / 15802]loss=0.0011154773870581075\n",
      "[6m 37s] Epoch 3[8000 / 15802]loss=0.0010909692803397774\n",
      "[6m 42s] Epoch 3[8400 / 15802]loss=0.0010758090595759096\n",
      "[6m 47s] Epoch 3[8800 / 15802]loss=0.0010495429926297881\n",
      "[6m 51s] Epoch 3[9200 / 15802]loss=0.001035913144764693\n",
      "[6m 55s] Epoch 3[9600 / 15802]loss=0.0010208615039785703\n",
      "[6m 59s] Epoch 3[10000 / 15802]loss=0.0010560088485479355\n",
      "[7m 3s] Epoch 3[10400 / 15802]loss=0.0010451761231972622\n",
      "[7m 7s] Epoch 3[10800 / 15802]loss=0.0010640315918458833\n",
      "[7m 12s] Epoch 3[11200 / 15802]loss=0.0010659378806927374\n",
      "[7m 16s] Epoch 3[11600 / 15802]loss=0.0010534046988548904\n",
      "[7m 20s] Epoch 3[12000 / 15802]loss=0.0010626607028146585\n",
      "[7m 24s] Epoch 3[12400 / 15802]loss=0.0010500753761058853\n",
      "[7m 28s] Epoch 3[12800 / 15802]loss=0.0010381540475646034\n",
      "[7m 32s] Epoch 3[13200 / 15802]loss=0.0010261030895917704\n",
      "[7m 36s] Epoch 3[13600 / 15802]loss=0.0010142133993041866\n",
      "[7m 40s] Epoch 3[14000 / 15802]loss=0.0009975943094385521\n",
      "[7m 44s] Epoch 3[14400 / 15802]loss=0.0009885191795830097\n",
      "[7m 48s] Epoch 3[14800 / 15802]loss=0.0009938377768707438\n",
      "[7m 52s] Epoch 3[15200 / 15802]loss=0.0009863650330685471\n",
      "[7m 57s] Epoch 3[15600 / 15802]loss=0.000990085913441502\n",
      "[7m 59s] Epoch 3[160 / 15802]loss=0.10519643479492516\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3436/4000 85.90%\n",
      "========================3========================\n",
      "[8m 8s] Epoch 4[400 / 15802]loss=0.0006527569890022278\n",
      "[8m 12s] Epoch 4[800 / 15802]loss=0.0007842165231704712\n",
      "[8m 16s] Epoch 4[1200 / 15802]loss=0.0013506218170126279\n",
      "[8m 20s] Epoch 4[1600 / 15802]loss=0.001238358449190855\n",
      "[8m 24s] Epoch 4[2000 / 15802]loss=0.0011665900275111198\n",
      "[8m 28s] Epoch 4[2400 / 15802]loss=0.00110532662520806\n",
      "[8m 31s] Epoch 4[2800 / 15802]loss=0.0011156360379287174\n",
      "[8m 35s] Epoch 4[3200 / 15802]loss=0.001095167580060661\n",
      "[8m 39s] Epoch 4[3600 / 15802]loss=0.0010910521778795454\n",
      "[8m 43s] Epoch 4[4000 / 15802]loss=0.0011493782997131347\n",
      "[8m 48s] Epoch 4[4400 / 15802]loss=0.0011784113706512884\n",
      "[8m 52s] Epoch 4[4800 / 15802]loss=0.0011527648475021125\n",
      "[8m 56s] Epoch 4[5200 / 15802]loss=0.0011535431587925324\n",
      "[9m 0s] Epoch 4[5600 / 15802]loss=0.0011247205095631736\n",
      "[9m 4s] Epoch 4[6000 / 15802]loss=0.001123436961323023\n",
      "[9m 8s] Epoch 4[6400 / 15802]loss=0.0011223700258415192\n",
      "[9m 12s] Epoch 4[6800 / 15802]loss=0.001147102115347105\n",
      "[9m 16s] Epoch 4[7200 / 15802]loss=0.0011206780239525769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9m 20s] Epoch 4[7600 / 15802]loss=0.0010964056418130272\n",
      "[9m 24s] Epoch 4[8000 / 15802]loss=0.0010901545956730843\n",
      "[9m 28s] Epoch 4[8400 / 15802]loss=0.0010688290434579055\n",
      "[9m 33s] Epoch 4[8800 / 15802]loss=0.0010467099017378958\n",
      "[9m 37s] Epoch 4[9200 / 15802]loss=0.0010348503153933132\n",
      "[9m 41s] Epoch 4[9600 / 15802]loss=0.0010152308208247025\n",
      "[9m 45s] Epoch 4[10000 / 15802]loss=0.000988403305411339\n",
      "[9m 49s] Epoch 4[10400 / 15802]loss=0.0009791199862957001\n",
      "[9m 53s] Epoch 4[10800 / 15802]loss=0.000971642702266022\n",
      "[9m 57s] Epoch 4[11200 / 15802]loss=0.0009576916894210236\n",
      "[10m 1s] Epoch 4[11600 / 15802]loss=0.0009395643908145099\n",
      "[10m 5s] Epoch 4[12000 / 15802]loss=0.0009255675741781791\n",
      "[10m 8s] Epoch 4[12400 / 15802]loss=0.0009529596248701696\n",
      "[10m 12s] Epoch 4[12800 / 15802]loss=0.0009421451430534944\n",
      "[10m 16s] Epoch 4[13200 / 15802]loss=0.0009391883224474662\n",
      "[10m 20s] Epoch 4[13600 / 15802]loss=0.0009362924109925242\n",
      "[10m 24s] Epoch 4[14000 / 15802]loss=0.0009287066640598433\n",
      "[10m 28s] Epoch 4[14400 / 15802]loss=0.0009335934350060092\n",
      "[10m 32s] Epoch 4[14800 / 15802]loss=0.0009442762627794936\n",
      "[10m 36s] Epoch 4[15200 / 15802]loss=0.0009363097114194381\n",
      "[10m 40s] Epoch 4[15600 / 15802]loss=0.0009276276225080856\n",
      "[10m 42s] Epoch 4[160 / 15802]loss=0.09271793123334646\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 2550/4000 63.75%\n",
      "========================4========================\n",
      "[10m 52s] Epoch 5[400 / 15802]loss=0.0012168753892183304\n",
      "[10m 56s] Epoch 5[800 / 15802]loss=0.000983585398644209\n",
      "[10m 59s] Epoch 5[1200 / 15802]loss=0.0008383590790132682\n",
      "[11m 3s] Epoch 5[1600 / 15802]loss=0.001348774335347116\n",
      "[11m 7s] Epoch 5[2000 / 15802]loss=0.001296074118465185\n",
      "[11m 11s] Epoch 5[2400 / 15802]loss=0.0011940657626837493\n",
      "[11m 15s] Epoch 5[2800 / 15802]loss=0.0011382300380085196\n",
      "[11m 19s] Epoch 5[3200 / 15802]loss=0.001057689085137099\n",
      "[11m 23s] Epoch 5[3600 / 15802]loss=0.0010223435651924874\n",
      "[11m 27s] Epoch 5[4000 / 15802]loss=0.0009651854187250138\n",
      "[11m 31s] Epoch 5[4400 / 15802]loss=0.0009423870542509989\n",
      "[11m 35s] Epoch 5[4800 / 15802]loss=0.0009014417479435603\n",
      "[11m 39s] Epoch 5[5200 / 15802]loss=0.000875603943490065\n",
      "[11m 43s] Epoch 5[5600 / 15802]loss=0.0008513396313147885\n",
      "[11m 47s] Epoch 5[6000 / 15802]loss=0.0008249581468602022\n",
      "[11m 52s] Epoch 5[6400 / 15802]loss=0.000856772813713178\n",
      "[11m 56s] Epoch 5[6800 / 15802]loss=0.0008425870997940793\n",
      "[12m 0s] Epoch 5[7200 / 15802]loss=0.0008211593785219722\n",
      "[12m 4s] Epoch 5[7600 / 15802]loss=0.0008103165775537491\n",
      "[12m 8s] Epoch 5[8000 / 15802]loss=0.0007989039719104767\n",
      "[12m 12s] Epoch 5[8400 / 15802]loss=0.0007845783508604481\n",
      "[12m 16s] Epoch 5[8800 / 15802]loss=0.0008007744454186071\n",
      "[12m 20s] Epoch 5[9200 / 15802]loss=0.0008536654386831367\n",
      "[12m 24s] Epoch 5[9600 / 15802]loss=0.0008641792895893256\n",
      "[12m 28s] Epoch 5[10000 / 15802]loss=0.0008658213138580322\n",
      "[12m 32s] Epoch 5[10400 / 15802]loss=0.0008602593036798331\n",
      "[12m 36s] Epoch 5[10800 / 15802]loss=0.0008495875158243709\n",
      "[12m 40s] Epoch 5[11200 / 15802]loss=0.0008473225643060037\n",
      "[12m 44s] Epoch 5[11600 / 15802]loss=0.0008465699414754736\n",
      "[12m 48s] Epoch 5[12000 / 15802]loss=0.0008383363870282967\n",
      "[12m 52s] Epoch 5[12400 / 15802]loss=0.0008327482965204023\n",
      "[12m 56s] Epoch 5[12800 / 15802]loss=0.0008259102201554924\n",
      "[13m 0s] Epoch 5[13200 / 15802]loss=0.0008129345100711693\n",
      "[13m 4s] Epoch 5[13600 / 15802]loss=0.0008100183861439719\n",
      "[13m 9s] Epoch 5[14000 / 15802]loss=0.000800324197858572\n",
      "[13m 12s] Epoch 5[14400 / 15802]loss=0.0007985931940169798\n",
      "[13m 16s] Epoch 5[14800 / 15802]loss=0.0007929722219705581\n",
      "[13m 20s] Epoch 5[15200 / 15802]loss=0.0007845215175889041\n",
      "[13m 24s] Epoch 5[15600 / 15802]loss=0.0007797910941716952\n",
      "[13m 26s] Epoch 5[160 / 15802]loss=0.09019150524400174\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 2652/4000 66.30%\n",
      "========================5========================\n",
      "[13m 36s] Epoch 6[400 / 15802]loss=0.0005267935618758202\n",
      "[13m 40s] Epoch 6[800 / 15802]loss=0.0005133948475122452\n",
      "[13m 44s] Epoch 6[1200 / 15802]loss=0.0005544795220096907\n",
      "[13m 48s] Epoch 6[1600 / 15802]loss=0.000541037363000214\n",
      "[13m 52s] Epoch 6[2000 / 15802]loss=0.0005952719934284687\n",
      "[13m 56s] Epoch 6[2400 / 15802]loss=0.000812985689068834\n",
      "[14m 0s] Epoch 6[2800 / 15802]loss=0.0007855986032102789\n",
      "[14m 4s] Epoch 6[3200 / 15802]loss=0.0007556919800117612\n",
      "[14m 9s] Epoch 6[3600 / 15802]loss=0.0007749070351322492\n",
      "[14m 12s] Epoch 6[4000 / 15802]loss=0.0007962299846112728\n",
      "[14m 16s] Epoch 6[4400 / 15802]loss=0.0007713874446397478\n",
      "[14m 20s] Epoch 6[4800 / 15802]loss=0.0007581262725094955\n",
      "[14m 24s] Epoch 6[5200 / 15802]loss=0.0007395382698338766\n",
      "[14m 28s] Epoch 6[5600 / 15802]loss=0.0007689465276364769\n",
      "[14m 32s] Epoch 6[6000 / 15802]loss=0.0007547025146583716\n",
      "[14m 36s] Epoch 6[6400 / 15802]loss=0.0007321313244756312\n",
      "[14m 40s] Epoch 6[6800 / 15802]loss=0.0007210344043286407\n",
      "[14m 44s] Epoch 6[7200 / 15802]loss=0.0007052626212437948\n",
      "[14m 48s] Epoch 6[7600 / 15802]loss=0.0006869610075495745\n",
      "[14m 52s] Epoch 6[8000 / 15802]loss=0.0006759431287646294\n",
      "[14m 56s] Epoch 6[8400 / 15802]loss=0.0006698751644719214\n",
      "[15m 0s] Epoch 6[8800 / 15802]loss=0.0006571199330077929\n",
      "[15m 4s] Epoch 6[9200 / 15802]loss=0.0006523702585178873\n",
      "[15m 8s] Epoch 6[9600 / 15802]loss=0.0006424078834243119\n",
      "[15m 12s] Epoch 6[10000 / 15802]loss=0.0006309823427349329\n",
      "[15m 16s] Epoch 6[10400 / 15802]loss=0.0006241087217886861\n",
      "[15m 20s] Epoch 6[10800 / 15802]loss=0.0006359539750135607\n",
      "[15m 24s] Epoch 6[11200 / 15802]loss=0.0006478058829504465\n",
      "[15m 28s] Epoch 6[11600 / 15802]loss=0.0006641820134145433\n",
      "[15m 32s] Epoch 6[12000 / 15802]loss=0.0006603061199809114\n",
      "[15m 36s] Epoch 6[12400 / 15802]loss=0.000697838606673383\n",
      "[15m 40s] Epoch 6[12800 / 15802]loss=0.0006949637018260546\n",
      "[15m 44s] Epoch 6[13200 / 15802]loss=0.0006958308711535099\n",
      "[15m 48s] Epoch 6[13600 / 15802]loss=0.000690581684877329\n",
      "[15m 52s] Epoch 6[14000 / 15802]loss=0.0006834420553807701\n",
      "[15m 56s] Epoch 6[14400 / 15802]loss=0.0006821183899107079\n",
      "[16m 0s] Epoch 6[14800 / 15802]loss=0.000679764020936312\n",
      "[16m 4s] Epoch 6[15200 / 15802]loss=0.0006785578861538517\n",
      "[16m 8s] Epoch 6[15600 / 15802]loss=0.0006720395832776259\n",
      "[16m 11s] Epoch 6[160 / 15802]loss=0.07138538712169976\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3021/4000 75.53%\n",
      "========================6========================\n",
      "[16m 21s] Epoch 7[400 / 15802]loss=0.0004152094013988972\n",
      "[16m 24s] Epoch 7[800 / 15802]loss=0.00042951712384819984\n",
      "[16m 29s] Epoch 7[1200 / 15802]loss=0.0004131670668721199\n",
      "[16m 33s] Epoch 7[1600 / 15802]loss=0.00042218826711177827\n",
      "[16m 37s] Epoch 7[2000 / 15802]loss=0.0005005966462194919\n",
      "[16m 41s] Epoch 7[2400 / 15802]loss=0.0005029837787151336\n",
      "[16m 45s] Epoch 7[2800 / 15802]loss=0.0005993438166167055\n",
      "[16m 49s] Epoch 7[3200 / 15802]loss=0.0006087498972192406\n",
      "[16m 53s] Epoch 7[3600 / 15802]loss=0.0005909834346837468\n",
      "[16m 57s] Epoch 7[4000 / 15802]loss=0.000588898641988635\n",
      "[17m 1s] Epoch 7[4400 / 15802]loss=0.0005901824225756255\n",
      "[17m 6s] Epoch 7[4800 / 15802]loss=0.0005895003179709116\n",
      "[17m 10s] Epoch 7[5200 / 15802]loss=0.0005855256433670337\n",
      "[17m 14s] Epoch 7[5600 / 15802]loss=0.0005854138479168926\n",
      "[17m 18s] Epoch 7[6000 / 15802]loss=0.0005692552762726942\n",
      "[17m 22s] Epoch 7[6400 / 15802]loss=0.0005726987065281719\n",
      "[17m 26s] Epoch 7[6800 / 15802]loss=0.000551042933948338\n",
      "[17m 30s] Epoch 7[7200 / 15802]loss=0.0005457136544605924\n",
      "[17m 34s] Epoch 7[7600 / 15802]loss=0.0005446870039266191\n",
      "[17m 38s] Epoch 7[8000 / 15802]loss=0.0005467724280897528\n",
      "[17m 42s] Epoch 7[8400 / 15802]loss=0.0005575947643124632\n",
      "[17m 46s] Epoch 7[8800 / 15802]loss=0.0005530522621914067\n",
      "[17m 50s] Epoch 7[9200 / 15802]loss=0.0005422945035135616\n",
      "[17m 54s] Epoch 7[9600 / 15802]loss=0.0005441884477234756\n",
      "[17m 58s] Epoch 7[10000 / 15802]loss=0.0005429065415635705\n",
      "[18m 2s] Epoch 7[10400 / 15802]loss=0.0005422946726545119\n",
      "[18m 7s] Epoch 7[10800 / 15802]loss=0.0005449123040738481\n",
      "[18m 11s] Epoch 7[11200 / 15802]loss=0.0005351266369689255\n",
      "[18m 15s] Epoch 7[11600 / 15802]loss=0.0005395764444858349\n",
      "[18m 19s] Epoch 7[12000 / 15802]loss=0.0005790274296887219\n",
      "[18m 23s] Epoch 7[12400 / 15802]loss=0.0005766275229172841\n",
      "[18m 27s] Epoch 7[12800 / 15802]loss=0.0005749332926643547\n",
      "[18m 31s] Epoch 7[13200 / 15802]loss=0.0005896689809125029\n",
      "[18m 35s] Epoch 7[13600 / 15802]loss=0.0006096865038168343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18m 39s] Epoch 7[14000 / 15802]loss=0.0006086624412398253\n",
      "[18m 43s] Epoch 7[14400 / 15802]loss=0.0006078225119401597\n",
      "[18m 47s] Epoch 7[14800 / 15802]loss=0.0006050675275509019\n",
      "[18m 51s] Epoch 7[15200 / 15802]loss=0.0006091528007221458\n",
      "[18m 55s] Epoch 7[15600 / 15802]loss=0.0006072533158107828\n",
      "[18m 57s] Epoch 7[160 / 15802]loss=0.08877596183447167\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3239/4000 80.97%\n",
      "========================7========================\n",
      "[19m 6s] Epoch 8[400 / 15802]loss=0.0005712172947824002\n",
      "[19m 10s] Epoch 8[800 / 15802]loss=0.0013558231014758348\n",
      "[19m 14s] Epoch 8[1200 / 15802]loss=0.0012657030982275803\n",
      "[19m 18s] Epoch 8[1600 / 15802]loss=0.0011653014039620757\n",
      "[19m 22s] Epoch 8[2000 / 15802]loss=0.0010899525620043278\n",
      "[19m 26s] Epoch 8[2400 / 15802]loss=0.001091458210721612\n",
      "[19m 30s] Epoch 8[2800 / 15802]loss=0.0010242660476693086\n",
      "[19m 34s] Epoch 8[3200 / 15802]loss=0.0010438381624408065\n",
      "[19m 38s] Epoch 8[3600 / 15802]loss=0.0010309049673378468\n",
      "[19m 42s] Epoch 8[4000 / 15802]loss=0.0009978597443550826\n",
      "[19m 46s] Epoch 8[4400 / 15802]loss=0.000983972405506806\n",
      "[19m 50s] Epoch 8[4800 / 15802]loss=0.0009666853413606684\n",
      "[19m 54s] Epoch 8[5200 / 15802]loss=0.0009443008168958701\n",
      "[19m 58s] Epoch 8[5600 / 15802]loss=0.0009090258686670236\n",
      "[20m 2s] Epoch 8[6000 / 15802]loss=0.0009093789768715699\n",
      "[20m 6s] Epoch 8[6400 / 15802]loss=0.0009177488309796899\n",
      "[20m 10s] Epoch 8[6800 / 15802]loss=0.0008980643760193797\n",
      "[20m 14s] Epoch 8[7200 / 15802]loss=0.0008767343612594737\n",
      "[20m 18s] Epoch 8[7600 / 15802]loss=0.000863897488697579\n",
      "[20m 22s] Epoch 8[8000 / 15802]loss=0.000845610098913312\n",
      "[20m 26s] Epoch 8[8400 / 15802]loss=0.0008391526572051502\n",
      "[20m 30s] Epoch 8[8800 / 15802]loss=0.0008783347091891549\n",
      "[20m 34s] Epoch 8[9200 / 15802]loss=0.0008722363218017247\n",
      "[20m 38s] Epoch 8[9600 / 15802]loss=0.000875405433277289\n",
      "[20m 42s] Epoch 8[10000 / 15802]loss=0.0008601613663136959\n",
      "[20m 46s] Epoch 8[10400 / 15802]loss=0.0008481199681185759\n",
      "[20m 50s] Epoch 8[10800 / 15802]loss=0.0008350211795833376\n",
      "[20m 54s] Epoch 8[11200 / 15802]loss=0.000827380799954491\n",
      "[20m 58s] Epoch 8[11600 / 15802]loss=0.0008207130335785191\n",
      "[21m 2s] Epoch 8[12000 / 15802]loss=0.0008115564119070769\n",
      "[21m 6s] Epoch 8[12400 / 15802]loss=0.00080897701964263\n",
      "[21m 10s] Epoch 8[12800 / 15802]loss=0.0008089635631768033\n",
      "[21m 14s] Epoch 8[13200 / 15802]loss=0.0007936772955299327\n",
      "[21m 18s] Epoch 8[13600 / 15802]loss=0.0007917828553849284\n",
      "[21m 22s] Epoch 8[14000 / 15802]loss=0.0007832329238631895\n",
      "[21m 26s] Epoch 8[14400 / 15802]loss=0.0007738478075609439\n",
      "[21m 30s] Epoch 8[14800 / 15802]loss=0.0007653684317562226\n",
      "[21m 34s] Epoch 8[15200 / 15802]loss=0.0007567235045625191\n",
      "[21m 38s] Epoch 8[15600 / 15802]loss=0.0007549823598506359\n",
      "[21m 40s] Epoch 8[160 / 15802]loss=0.0748193682404235\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3045/4000 76.12%\n",
      "========================8========================\n",
      "[21m 50s] Epoch 9[400 / 15802]loss=0.00035678829066455365\n",
      "[21m 54s] Epoch 9[800 / 15802]loss=0.0005628611287102104\n",
      "[21m 58s] Epoch 9[1200 / 15802]loss=0.0007479026820510626\n",
      "[22m 2s] Epoch 9[1600 / 15802]loss=0.0006822939752601087\n",
      "[22m 6s] Epoch 9[2000 / 15802]loss=0.0006655714008957147\n",
      "[22m 10s] Epoch 9[2400 / 15802]loss=0.000627789020848771\n",
      "[22m 14s] Epoch 9[2800 / 15802]loss=0.0005989702431751149\n",
      "[22m 18s] Epoch 9[3200 / 15802]loss=0.000571057042106986\n",
      "[22m 22s] Epoch 9[3600 / 15802]loss=0.0005678046805163224\n",
      "[22m 26s] Epoch 9[4000 / 15802]loss=0.000551492016762495\n",
      "[22m 30s] Epoch 9[4400 / 15802]loss=0.000556205724450675\n",
      "[22m 34s] Epoch 9[4800 / 15802]loss=0.0005429582608242829\n",
      "[22m 38s] Epoch 9[5200 / 15802]loss=0.0005429035969651663\n",
      "[22m 42s] Epoch 9[5600 / 15802]loss=0.0005481259112379381\n",
      "[22m 46s] Epoch 9[6000 / 15802]loss=0.0005690124792357286\n",
      "[22m 50s] Epoch 9[6400 / 15802]loss=0.0005620672123041004\n",
      "[22m 54s] Epoch 9[6800 / 15802]loss=0.000559021924786708\n",
      "[22m 58s] Epoch 9[7200 / 15802]loss=0.0005496070477076703\n",
      "[23m 2s] Epoch 9[7600 / 15802]loss=0.0005647071357816458\n",
      "[23m 6s] Epoch 9[8000 / 15802]loss=0.0005499942940659821\n",
      "[23m 10s] Epoch 9[8400 / 15802]loss=0.0005457466029162918\n",
      "[23m 14s] Epoch 9[8800 / 15802]loss=0.000559966291978278\n",
      "[23m 18s] Epoch 9[9200 / 15802]loss=0.0005469204772911642\n",
      "[23m 23s] Epoch 9[9600 / 15802]loss=0.000550662960158661\n",
      "[23m 27s] Epoch 9[10000 / 15802]loss=0.0005506672739982605\n",
      "[23m 31s] Epoch 9[10400 / 15802]loss=0.0005476144740644555\n",
      "[23m 35s] Epoch 9[10800 / 15802]loss=0.0005412426415003008\n",
      "[23m 39s] Epoch 9[11200 / 15802]loss=0.0005397722234816424\n",
      "[23m 43s] Epoch 9[11600 / 15802]loss=0.0005429365437734743\n",
      "[23m 47s] Epoch 9[12000 / 15802]loss=0.0005357433743774891\n",
      "[23m 51s] Epoch 9[12400 / 15802]loss=0.0005331162483461441\n",
      "[23m 55s] Epoch 9[12800 / 15802]loss=0.0005587343085790053\n",
      "[23m 59s] Epoch 9[13200 / 15802]loss=0.0005554952483737107\n",
      "[24m 3s] Epoch 9[13600 / 15802]loss=0.0005576230793753091\n",
      "[24m 7s] Epoch 9[14000 / 15802]loss=0.0005578131590570722\n",
      "[24m 11s] Epoch 9[14400 / 15802]loss=0.000560281569034689\n",
      "[24m 15s] Epoch 9[14800 / 15802]loss=0.0005595444792227166\n",
      "[24m 19s] Epoch 9[15200 / 15802]loss=0.0005560003132804444\n",
      "[24m 23s] Epoch 9[15600 / 15802]loss=0.0005492847460584763\n",
      "[24m 25s] Epoch 9[160 / 15802]loss=0.0565508539788425\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3046/4000 76.15%\n",
      "========================9========================\n",
      "[24m 34s] Epoch 10[400 / 15802]loss=0.0008304528146982193\n",
      "[24m 38s] Epoch 10[800 / 15802]loss=0.00066719900816679\n",
      "[24m 42s] Epoch 10[1200 / 15802]loss=0.0005467686429619789\n",
      "[24m 47s] Epoch 10[1600 / 15802]loss=0.0005729005206376314\n",
      "[24m 51s] Epoch 10[2000 / 15802]loss=0.0005259372275322675\n",
      "[24m 55s] Epoch 10[2400 / 15802]loss=0.0005017456862454613\n",
      "[24m 59s] Epoch 10[2800 / 15802]loss=0.00048615435803575174\n",
      "[25m 3s] Epoch 10[3200 / 15802]loss=0.0004793306905776262\n",
      "[25m 7s] Epoch 10[3600 / 15802]loss=0.0004888289256228341\n",
      "[25m 11s] Epoch 10[4000 / 15802]loss=0.0005015055891126394\n",
      "[25m 15s] Epoch 10[4400 / 15802]loss=0.0004917384345423092\n",
      "[25m 19s] Epoch 10[4800 / 15802]loss=0.0004992721664408842\n",
      "[25m 23s] Epoch 10[5200 / 15802]loss=0.0005117258400871204\n",
      "[25m 27s] Epoch 10[5600 / 15802]loss=0.0005183575076184102\n",
      "[25m 31s] Epoch 10[6000 / 15802]loss=0.0005168132595717907\n",
      "[25m 35s] Epoch 10[6400 / 15802]loss=0.0005015033832751214\n",
      "[25m 39s] Epoch 10[6800 / 15802]loss=0.0005703903942861978\n",
      "[25m 43s] Epoch 10[7200 / 15802]loss=0.0005712141903738181\n",
      "[25m 47s] Epoch 10[7600 / 15802]loss=0.0005607829688999214\n",
      "[25m 51s] Epoch 10[8000 / 15802]loss=0.0005587634961120784\n",
      "[25m 55s] Epoch 10[8400 / 15802]loss=0.0005548421297931954\n",
      "[25m 59s] Epoch 10[8800 / 15802]loss=0.000557747175493701\n",
      "[26m 3s] Epoch 10[9200 / 15802]loss=0.0005540425156283638\n",
      "[26m 7s] Epoch 10[9600 / 15802]loss=0.0005489242569698641\n",
      "[26m 11s] Epoch 10[10000 / 15802]loss=0.0005480375844985247\n",
      "[26m 15s] Epoch 10[10400 / 15802]loss=0.0005505091105945982\n",
      "[26m 19s] Epoch 10[10800 / 15802]loss=0.0005432366386607841\n",
      "[26m 23s] Epoch 10[11200 / 15802]loss=0.0005337622375892741\n",
      "[26m 27s] Epoch 10[11600 / 15802]loss=0.0005346118132102079\n",
      "[26m 31s] Epoch 10[12000 / 15802]loss=0.0005329270462195078\n",
      "[26m 35s] Epoch 10[12400 / 15802]loss=0.0005266151886673704\n",
      "[26m 39s] Epoch 10[12800 / 15802]loss=0.00052226607571356\n",
      "[26m 43s] Epoch 10[13200 / 15802]loss=0.000523165784437548\n",
      "[26m 48s] Epoch 10[13600 / 15802]loss=0.0005184138916871127\n",
      "[26m 52s] Epoch 10[14000 / 15802]loss=0.0005157098182077918\n",
      "[26m 56s] Epoch 10[14400 / 15802]loss=0.0005141476720261077\n",
      "[27m 0s] Epoch 10[14800 / 15802]loss=0.0005086922434133452\n",
      "[27m 4s] Epoch 10[15200 / 15802]loss=0.0005084008343615815\n",
      "[27m 8s] Epoch 10[15600 / 15802]loss=0.0005021585871537145\n",
      "[27m 10s] Epoch 10[160 / 15802]loss=0.0610484192497097\n",
      "evaluating trained model ...\n",
      "Test set:Accuracy 3112/4000 77.80%\n",
      "========================10========================\n"
     ]
    }
   ],
   "source": [
    "import torch, time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Parameters\n",
    "HIDDEN_SIZE = 200\n",
    "BATCH_SIZE = 200 #每一批训练10个异常子序列中的相同位置的数据\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 10 #训练周期\n",
    "N_CHARS = 1500 #输入字符集128个字典长度\n",
    "USE_GPU = False\n",
    "\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = 'train.csv' if is_train_set else 'test.csv'\n",
    "        with open(filename, 'rt') as f:\n",
    "            next(f)   # skip the first line\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader) #读取数据，以元组形式（name,country)\n",
    "        self.sequences = [str(row[0:-1]) for row in rows] #把异常子序列放在names列表中\n",
    "        self.len = len(self.sequences) #求出所有名字的个数\n",
    "        self.classes = [row[-1] for row in rows] #把异常子序列标签放在countries列表中\n",
    "        self.class_list = list(sorted(set(self.classes))) #把异常子序列类别去重并排序，然后转为列表\n",
    "        self.class_num = len(self.class_list) #求出异常子序列类别个数\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.classes[index] #拿出的名字是异常子序列串，拿出的国家是标签\n",
    "    def __len__(self):\n",
    "        return self.len #返回名字个数，即数据集的长度\n",
    "    def getclassesNum(self):\n",
    "        return self.class_num#获得异常子序列的类别个数\n",
    "\n",
    "trainset = SequenceDataset(is_train_set=True)#获取训练集，每批10个异常子序列中的某个数据\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testset = SequenceDataset(is_train_set=False)#获取测试集，每批10个异常子序列中的某个数据\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "N_COUNTRY = trainset.getclassesNum()#获得异常类别数量，决定模型最终输出的维度大小\n",
    "\n",
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        #没有层数输入时，默认选用1层双向GRU，输出两个hidden，hf,hb\n",
    "        #RNNClassifier(N_CHARS=1500, HIDDEN_SIZE=200, N_COUNTRY=2, N_LAYER=2)\n",
    "        \n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size#200\n",
    "        self.n_layers = n_layers#2\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        #(1500，200)，embedding输入(seqlen,batchsize),输出(seqlen,batchsize,hiddensize)，将名字和字母嵌入成gru要求的输入的形式\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        #GRU输入(seqlen,batch_size,hidden_size)，hidden(𝑛𝐿𝑎𝑦𝑒𝑟𝑠∗𝑛𝐷𝑖𝑟𝑒𝑐𝑡𝑖𝑜𝑛𝑠,𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒,ℎ𝑖𝑑𝑑𝑒𝑛𝑆𝑖𝑧𝑒)\n",
    "        #GRU输出𝑜𝑢𝑡𝑝𝑢𝑡:𝑠𝑒𝑞𝐿𝑒𝑛,𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒,ℎ𝑖𝑑𝑑𝑒𝑛𝑆𝑖𝑧𝑒∗𝑛𝐷𝑖𝑟𝑒𝑐𝑡𝑖𝑜𝑛𝑠，hidden(𝑛𝐿𝑎𝑦𝑒𝑟𝑠∗𝑛𝐷𝑖𝑟𝑒𝑐𝑡𝑖𝑜𝑛𝑠,𝑏𝑎𝑡𝑐ℎ𝑆𝑖𝑧𝑒,ℎ𝑖𝑑𝑑𝑒𝑛𝑆𝑖𝑧𝑒)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "        #再经过fc将(s,b,h*nd)转为(s,b,o)，然后用交叉熵计算损失来训练\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)#h0为(nl*nd,b,h)的全0初始隐藏层\n",
    "        return create_tensor(hidden)\n",
    "    \n",
    "    def forward(self, input_, seq_lengths):\n",
    "        #output = classifier(inputs, seq_lengths)\n",
    "        # input shape : B x S --> S x B，B是每批次取的名字数量，S是每个名字的字母长度，竖排变横排，即对应字母对齐变横排\n",
    "        input_ = input_.t()#转置为seqlen x batch_size\n",
    "        batch_size = input_.size(1)#每批次取的名字数量256,为了初始化h0\n",
    "        \n",
    "        hidden = self._init_hidden(batch_size)#生成（2*2，10，200）全0\n",
    "        embedding = self.embedding(input_)#30*10,600->43*10*200\n",
    "        #(600，200)，embedding输入(seqlen名字长度,batchsize选一批名字),输出(seqlen,batchsize,200)，将名字和字母嵌入成gru要求的输入的形式\n",
    "        \n",
    "        # pack them up，为了提高运行效率，面对序列长短不一时支持提速，目的是使填充为0的数据不需要参与运算，生成一个打包的对象\n",
    "        #（一个长条的向量，每一小段向量对应一个字符串里不为0的数据序列，且是降序排序好的）\n",
    "        gru_input = torch.nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths) #输出见p67页\n",
    "        #seq_lengths：每个batch里名字字母序列长度放到列表里给它，经过packed后返回一个打包的Squence对象(data是按batch竖排的数据，batch)。\n",
    "        \n",
    "        output, hidden = self.gru(gru_input, hidden)#要了解以下GRU的结构\n",
    "        #The output is a PackedSequence object, actually it is a tuple。输出hidden是(nl*nd,b,h)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output.view(-1, N_COUNTRY)\n",
    "\n",
    "def sequence2list(sequences):\n",
    "    #返回字符对应的每个字母的十进制整数，这个十进制数其实对应的是独热向量，在嵌入的时候只要告诉他ascii码值就行\n",
    "    arr_temp = []\n",
    "    arr_temp1 = []\n",
    "    for sequence in sequences:\n",
    "        sequence = sequence.strip(\"']['\").split(\"', '\")\n",
    "#         print(sequence)\n",
    "        sequence = np.array([float(c) for c in sequence])\n",
    "        sequence = np.round(sequence,2)\n",
    "        arr_temp.append(sequence)\n",
    "    sequence_min = np.min(arr_temp)\n",
    "    arr = []\n",
    "    for sequence in arr_temp: \n",
    "        arr_temp1 = [int((c-sequence_min)/0.01) for c in sequence]\n",
    "        arr.append((arr_temp1,len(arr_temp1)))\n",
    "#     print(arr)\n",
    "    return arr\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "#长度一样的序列可以不用排序\n",
    "def make_tensors(sequences, classes):\n",
    "    sequences_and_lengths = sequence2list(sequences)#[(每个序列的数字十进制数列表，序列的长度),....]\n",
    "    seq_tensor = torch.LongTensor([s1[0] for s1 in sequences_and_lengths])#取出名字十进制数列表，num*名字十进制列表\n",
    "    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_lengths])#取出名字长度列表转为longtensor，[seqlen]\n",
    "    classes = torch.LongTensor(np.array(classes).astype(int).tolist())#将国家转为longtensor\n",
    "    \n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(classes)\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m,s)\n",
    "\n",
    "def drawAcc(acc_list):\n",
    "    epoch = np.arange(1, len(acc_list)+1, 1)\n",
    "    acc_list = np.array(acc_list)\n",
    "    plt.plot(epoch, acc_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (sequences, classes) in enumerate(train_loader, 1):#取出名字和国家\n",
    "        inputs, seq_lengths, target = make_tensors(sequences, classes)#排序后的十进制矩阵，排序后的序列长度列表，排序后的国家列表\n",
    "#         print(inputs)\n",
    "#         print(seq_lengths)\n",
    "#         print(target)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "#         print(output)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "#         print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #每5个batch输出一次\n",
    "        if i % 2 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch}', end='')\n",
    "            print(f'[{i * len(inputs)} / {len(trainset)}]',end='')#每批10,每5批输出一次损失\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "    return total_loss\n",
    "\n",
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model ...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (sequences, classes) in enumerate(test_loader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(sequences, classes)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "#             print(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        percent = '%.2f' % (100 * correct/total)\n",
    "        print(f'Test set:Accuracy {correct}/{total} {percent}%')\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)#N_CHARS\n",
    "    #def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True)\n",
    "    #是否用GPU跑\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "    print('-'*50)\n",
    "    acc_list = []\n",
    "    best_model = 0\n",
    "    for epoch in range(1 , N_EPOCHS + 1):\n",
    "        # Train cycle\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc)\n",
    "        print('='*24+str(epoch)+'='*24)\n",
    "        # 保存神经网络\n",
    "        if acc > best_model:\n",
    "            best_model = acc\n",
    "            torch.save(classifier, 'best_classifier_model.pkl')           # 保存整个神经网络的结构和模型参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画出epoch和准确度变化曲线\n",
    "drawAcc(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained model ...\n",
      "Test set:Accuracy 6589/10000 65.89%\n"
     ]
    }
   ],
   "source": [
    "# 载入整个神经网络的结构及其模型参数 ,查看最优的模型，并用于异常子序列分类任务\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = 'train.csv' if is_train_set else 'real_test.csv'\n",
    "        with open(filename, 'rt') as f:\n",
    "            next(f)   # skip the first line\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader) #读取数据，以元组形式（name,country)\n",
    "#         self.flarename = [row[0] for row in rows]\n",
    "        self.sequences = [str(row[2:-1]) for row in rows] #把异常子序列放在names列表中\n",
    "        self.len = len(self.sequences) #求出所有名字的个数\n",
    "        self.classes = [row[-1] for row in rows] #把异常子序列标签放在countries列表中\n",
    "        self.class_list = list(sorted(set(self.classes))) #把异常子序列类别去重并排序，然后转为列表\n",
    "        self.class_num = len(self.class_list) #求出异常子序列类别个数\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.classes[index] #拿出的名字是异常子序列串，拿出的国家是标签\n",
    "    def __len__(self):\n",
    "        return self.len #返回名字个数，即数据集的长度\n",
    "    def getclassesNum(self):\n",
    "        return self.class_num#获得异常子序列的类别个数\n",
    "\n",
    "testset = SequenceDataset(is_train_set=False)#获取测试集，每批10个异常子序列中的某个数据\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "N_COUNTRY = trainset.getclassesNum()#获得异常类别数量，决定模型最终输出的维度大小\n",
    "\n",
    "\n",
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model ...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (sequences, classes) in enumerate(test_loader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(sequences, classes)\n",
    "#             print(target)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            with open('./real_test_label.csv', 'a+', newline='') as f:\n",
    "#                 next(f)   # skip the first line\n",
    "                csv_writer = csv.writer(f)\n",
    "                for l in pred:\n",
    "                    csv_writer.writerow(l)    \n",
    "        \n",
    "        \n",
    "        percent = '%.2f' % (100 * correct/total)\n",
    "        print(f'Test set:Accuracy {correct}/{total} {percent}%')\n",
    "    return correct/total\n",
    "\n",
    "classifier = torch.load('best_classifier_model.pkl')\n",
    "acc = testModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
